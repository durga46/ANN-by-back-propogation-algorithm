### EX NO : 
### DATE  :
# <p align="center"> ANN BY BACK PROPAGATION ALGORITHM </p>
## Aim:
   To implement multi layer artificial neural network using back propagation algorithm.
## Equipments Required:
1. Hardware – PCs
2. Anaconda – Python 3.7 Installation / Moodle-Code Runner /Google Colab

## Related Theory Concept:
Related Theory  Concept: 

 Algorithm for ANN Backpropagation: 
• Weight initialization: 
        Set all weights and node thresholds to small random numbers. Note that the node threshold is the negative of the weight from the bias unit(whose activation level is fixed at 1). 

• Calculation of Activation: 
1.	The activation level of an input is determined by the instance presented to the network. 
2.	The activation level oj of a hidden and output unit is determined. 

• Weight training: 
1.	Start at the output units and work backward to the hidden layer recursively and adjust weights. 
2.	The weight change is completed. 
3.	The error gradient is given by: 

a.	For the output units. 
b.	For the hidden units. 

4.	Repeat iterations until convergence in term of the selected error criterion. An iteration includes presenting an instance, calculating activation and modifying weights. 

## Algorithm
1.
2.
3.
4.

## Program:
```
/*
Program to implement ANN by back propagation algorithm.
Developed by   :
RegisterNumber :  
*/
```

## Output:
![ANN by back propagation algorithm](XXX.png)


## Result:
Thus the python program successully implemented multi layer artificial neural network using back propagation algorithm.
